{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055d00cb-704e-4b12-92b1-8165173a0c9a",
   "metadata": {},
   "source": [
    "# Отработка модели #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23443613-d099-4879-8f92-0d221d2e9ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##### pip install category_encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "##### pip install scikit-learn\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "##### from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "##### pip install imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d66ac115-b750-45e3-8acd-91f3119de65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 322 entries, 0 to 321\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   date             322 non-null    object\n",
      " 1   id               322 non-null    object\n",
      " 2   utc              322 non-null    object\n",
      " 3   steck            321 non-null    object\n",
      " 4   spec             322 non-null    object\n",
      " 5   role             322 non-null    object\n",
      " 6   role_in          322 non-null    object\n",
      " 7   hour_per_week    322 non-null    object\n",
      " 8   other_courses    322 non-null    object\n",
      " 9   time_of_studies  322 non-null    object\n",
      " 10  notes            99 non-null     object\n",
      " 11  language         205 non-null    object\n",
      " 12  in_chat          322 non-null    object\n",
      " 13  out              31 non-null     object\n",
      "dtypes: object(14)\n",
      "memory usage: 35.3+ KB\n"
     ]
    }
   ],
   "source": [
    "ini_df = pd.read_csv('data/anketa_new.csv', sep='^')\n",
    "ini_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "28d2f7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "out\n",
       "Выбыл    31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_df['out'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a2241bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_df['out'] = ini_df['out'].apply(lambda x: 1 if x == 'Выбыл' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aced9b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "out\n",
       "0    291\n",
       "1     31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ini_df['out'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66616c9c-1c55-4172-84e4-5ef63eef908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_df = ini_df.drop(['out'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3344dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 322 entries, 0 to 321\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   date             322 non-null    object\n",
      " 1   id               322 non-null    object\n",
      " 2   utc              322 non-null    object\n",
      " 3   steck            321 non-null    object\n",
      " 4   spec             322 non-null    object\n",
      " 5   role             322 non-null    object\n",
      " 6   role_in          322 non-null    object\n",
      " 7   hour_per_week    322 non-null    object\n",
      " 8   other_courses    322 non-null    object\n",
      " 9   time_of_studies  322 non-null    object\n",
      " 10  notes            99 non-null     object\n",
      " 11  language         205 non-null    object\n",
      " 12  in_chat          322 non-null    object\n",
      "dtypes: object(13)\n",
      "memory usage: 32.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ini_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a634f34-2f4b-4942-a023-7bb76d6d1906",
   "metadata": {},
   "source": [
    "# Новая модель #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1589726e-5e17-4e28-9a95-2813400793e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(row):\n",
    "    data = row\n",
    "    data = data.drop(['in_chat'], axis=1) # Дроп неинформативного признака\n",
    "\n",
    "    # Работа с датой и временем\n",
    "    data['date'] = pd.to_datetime(data['date'], dayfirst=True)\n",
    "    data['day_name'] = data['date'].dt.day_name()\n",
    "    data['day_num'] = data['date'].dt.day_of_week\n",
    "    data['hour_of_day'] = data['date'].dt.hour\n",
    "\n",
    "    to_fill = {\n",
    "        'day_name': 'Friday',\n",
    "        'day_num': data['day_num'].median(),\n",
    "        'hour_of_day': data['hour_of_day'].median()\n",
    "        }\n",
    "    data = data.fillna(to_fill)\n",
    "\n",
    "    def get_period(x):\n",
    "        if 0 < x < 11:\n",
    "            return 'morning'\n",
    "        elif 11 < x < 17:\n",
    "            return 'day'\n",
    "        elif 17 < x < 23:\n",
    "            return 'evening'\n",
    "        else:\n",
    "            return 'night'\n",
    "\n",
    "    data['period_of_day'] = data['hour_of_day'].apply(get_period)\n",
    "\n",
    "    # ЯП\n",
    "    data['language'].fillna('нуль') # запроняем пропуски\n",
    "\n",
    "    def get_java(x): # выделяем джаву и джс\n",
    "        if str(x).lower() == 'js':\n",
    "            return 'java'\n",
    "        else:\n",
    "            return str(x).lower()\n",
    "\n",
    "    data['language'] = data['language'].apply(get_java)\n",
    "\n",
    "    languages = [\n",
    "        'python',\n",
    "        'js',\n",
    "        'java',\n",
    "        'c#',\n",
    "        'golang',\n",
    "        'php',\n",
    "        'c++',\n",
    "        'flutter',\n",
    "        'qa',\n",
    "        'sql'\n",
    "        ]\n",
    "\n",
    "    for lang in languages: # бинарное кодирование ЯП\n",
    "        data[lang] = data['language'].apply(lambda x: 1 if lang in str(x).lower() else 0)\n",
    "\n",
    "    # Роль\n",
    "\n",
    "    def get_role(x):\n",
    "        if 'backend' in str(x).lower() or 'back' in str(x).lower() or 'бэк' in str(x).lower():\n",
    "            return 'backend'\n",
    "        elif 'frontend' in str(x).lower() or 'front' in str(x).lower() or 'фронт' in str(x).lower():\n",
    "            return 'frontend'\n",
    "        elif 'аналит' in str(x).lower() or 'analys' in str(x).lower() or 'ba' in str(x).lower():\n",
    "            return 'аналитик'\n",
    "        elif 'ds' in str(x).lower() or 'scient' in str(x).lower():\n",
    "            return 'data scientist'\n",
    "        elif 'дизайн' in str(x).lower() or 'design' in str(x).lower() or 'UX' in str(x).lower():\n",
    "            return 'дизайнер'\n",
    "        elif 'project' in str(x).lower() or 'проект' in str(x).lower():\n",
    "            return 'project manager'\n",
    "        elif 'android' in str(x).lower():\n",
    "            return 'android'\n",
    "        elif 'ios' in str(x).lower():\n",
    "            return 'ios'\n",
    "        elif 'full' in str(x).lower() or 'develop' in str(x).lower() or 'разраб' in str(x).lower() or 'программ' in str(x).lower():\n",
    "            return 'fullstack'\n",
    "        elif 'админ' in str(x).lower():\n",
    "            return 'системный администратор'\n",
    "        elif 'dev' in str(x).lower():\n",
    "            return 'devops'\n",
    "        elif 'qa' in str(x).lower() or 'тест' in str(x).lower() or 'test' in str(x).lower():\n",
    "            return 'тестировщик'\n",
    "        else:\n",
    "            return 'other'\n",
    "\n",
    "    data['role_in_new'] = data['role_in'].apply(get_role)\n",
    "    data['test_role'] = data['role'].apply(get_role)\n",
    "\n",
    "    def to_compar(row):\n",
    "        if str(row['test_role']).lower() == str(row['role_in_new']).lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    data['compar_role'] = data.apply(to_compar, axis=1)\n",
    "\n",
    "    # Время на практику\n",
    "    def get_time(x):\n",
    "        if '10+ часов' in x:\n",
    "            return 0\n",
    "        if '20+ часов' in x:\n",
    "            return 1\n",
    "        if 'готов работать 25/8' in x:\n",
    "            return 2\n",
    "\n",
    "    data['time_par_week'] = data['hour_per_week'].apply(get_time)\n",
    "\n",
    "    # работа с признаками steck и spec\n",
    "    data['steck'] = data['steck'].fillna('unknown')\n",
    "    data['spec'] = data['spec'].fillna('unknown')\n",
    "\n",
    "    def text_clear(text):\n",
    "        import string\n",
    "        for p in string.punctuation + '\\n':\n",
    "            if p in text:\n",
    "                text = text.replace(p, '')\n",
    "        return text\n",
    "\n",
    "    data['steck'] = data['steck'].apply(text_clear)\n",
    "    data['spec'] = data['spec'].apply(text_clear)\n",
    "\n",
    "    data['steck'] = data['steck'].apply(lambda x: x.split())\n",
    "    data['spec'] = data['spec'].apply(lambda x: x.split())\n",
    "\n",
    "    def length(iterrows):\n",
    "        for row in iterrows:\n",
    "            if 1 < len(row) <=2:\n",
    "                return 1\n",
    "            if 3 < len(row) <=4:\n",
    "                return 2\n",
    "            if 5 < len(row) <=7:\n",
    "                return 3\n",
    "            if len(row) > 7:\n",
    "                return 4\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "    data['steck_count'] = data['steck'].apply(length)\n",
    "    data['spec'] = data['spec'].apply(length)\n",
    "    data['steck_count'] = data['steck_count'].fillna(0)\n",
    "\n",
    "    # Чистка и кодирование\n",
    "    data = pd.get_dummies(data, columns=['day_name', 'period_of_day'])\n",
    "\n",
    "    bin_encoder = ce.BinaryEncoder(cols=['role', 'role_in'])\n",
    "    bin = bin_encoder.fit_transform(data[['role', 'role_in']])\n",
    "    data = pd.concat([data, bin], axis=1)\n",
    "\n",
    "    data = data.drop(['hour_of_day', 'qa', 'role_in', 'notes', 'date'], axis=1)\n",
    "\n",
    "    object_columns = [s for s in data.columns if data[s].dtypes == 'object']\n",
    "    data.drop(object_columns, axis = 1, inplace=True)\n",
    "\n",
    "    with open('data/scaler.pkl', 'rb') as pkl_file: # уточнить адрес файла\n",
    "        scaler = pickle.load(pkl_file)\n",
    "\n",
    "    with open('data/model_lr.pkl', 'rb') as pkl_file: # уточнить адрес файла\n",
    "        model_lr = pickle.load(pkl_file)\n",
    "\n",
    "    with open('data/model_rf.pkl', 'rb') as pkl_file: # уточнить адрес файла\n",
    "        model_rf = pickle.load(pkl_file)\n",
    "\n",
    "    threshold_lr_rf = 0.45\n",
    "\n",
    "    data_s = scaler.transform(data)\n",
    "\n",
    "    y_lr_pred = pd.Series(model_lr.predict_proba(data_s)[:, 1])\n",
    "    y_lr_class = y_lr_pred.apply(lambda x: 1 if x > threshold_lr_rf else 0)\n",
    "\n",
    "    y_rf_pred = pd.Series(model_rf.predict_proba(data)[:, 1])\n",
    "    y_rf_class = y_rf_pred.apply(lambda x: 1 if x > threshold_lr_rf else 0)\n",
    "\n",
    "    test = pd.DataFrame({\n",
    "        'rf_pred': list(y_rf_pred),\n",
    "        'rf_class': y_rf_class,\n",
    "        'lr_pred': list(y_lr_pred),\n",
    "        'lr_class': y_lr_class\n",
    "        })\n",
    "\n",
    "    with open('data/model_dt.pkl', 'rb') as pkl_file: # уточнить адрес файла\n",
    "        model_dt = pickle.load(pkl_file)\n",
    "\n",
    "    y_dt_pred = pd.Series(model_dt.predict_proba(test)[:, 1])\n",
    "    df = pd.concat([row, y_dt_pred], axis=1)\n",
    "    df.columns = [\n",
    "        'date',\n",
    "        'id',\n",
    "        'utc',\n",
    "        'steck',\n",
    "        'spec',\n",
    "        'role',\n",
    "        'role_in',\n",
    "        'hour_per_week',\n",
    "        'other_courses',\n",
    "        'time_of_studies',\n",
    "        'notes',\n",
    "        'language',\n",
    "        'in_chat',\n",
    "        'fin_pred'\n",
    "        ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6aa9a9d-da97-49d0-9f60-7e2a9f011c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stalk\\AppData\\Local\\Temp\\ipykernel_5504\\2716173766.py:6: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  data['date'] = pd.to_datetime(data['date'], dayfirst=True)\n",
      "C:\\Programs\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RobustScaler from version 1.2.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Programs\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Programs\\Python310\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mini_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 162\u001b[0m, in \u001b[0;36mprediction\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m    159\u001b[0m     model_lr \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(pkl_file)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/model_rf.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pkl_file: \u001b[38;5;66;03m# уточнить адрес файла\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m     model_rf \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkl_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m threshold_lr_rf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.45\u001b[39m\n\u001b[0;32m    166\u001b[0m data_s \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(data)\n",
      "File \u001b[1;32msklearn\\\\tree\\\\_tree.pyx:865\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.__setstate__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\\\tree\\\\_tree.pyx:1571\u001b[0m, in \u001b[0;36msklearn.tree._tree._check_node_ndarray\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]"
     ]
    }
   ],
   "source": [
    "new_df = prediction(ini_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a480140-a297-42a3-901a-096c16f0ed80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
